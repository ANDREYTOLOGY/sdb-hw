# Домашнее задание к занятию "`Кеширование Redis/memcached`" - `Чернышов Андрей`

### Задание 1
### Кеширование
Приведите примеры проблем, которые может решить кеширование.

*Повышение производительности и снижение задержки: Кеширование данных в быстрой памяти (например, оперативной памяти) позволяет получать к ним доступ в сотни раз быстрее, чем при обращении к основному источнику (базе данных на диске). Это особенно критично для часто запрашиваемой информации. 
Увеличение скорости ответа: обеспечивается благодаря сокращению времени доступа к данным по сравнению с основным источником;
Снижение нагрузки на backend-системы (Database Offload): Каждый запрос, который обслуживается из кеша, не доходит до базы данных. Это предотвращает ее перегрузку в периоды пиковой активности (например, во время распродаж, рекламных кампаний) и позволяет обслуживать больше пользователей на том же hardware.  
Экономия ресурсов базы данных происходит путем разгрузки от повторяющихся сложных вычислений и частых запросов;
Обработка "горячих" ключей: Некоторые данные могут запрашиваться тысячи раз в секунду. Кеширование таких данных предотвращает постоянные обращения к базе данных и потенциальные "точки отказа".*

### Задание 2. Memcached
Скриншот systemctl status memcached
![systemctl status memcached](https://github.com/ANDREYTOLOGY/sdb-hw/blob/main/img/status_memcached.png)

### Задание 3. Удаление по TTL в Memcached
Запишите в memcached несколько ключей с любыми именами и значениями, для которых выставлен TTL 5.
![del key memcached](https://github.com/ANDREYTOLOGY/sdb-hw/blob/main/img/del_key_memcached.png)

3.1.* Какие, на ваш взгляд, преимущества у NewSQL систем перед SQL и NoSQL.

*Перед SQL -	Масштабируемость: Легко масштабируются горизонтально (добавлением серверов) для обработки огромных нагрузок, оставаясь при этом такими же быстрыми.  
Перед NoSQL - Полная поддержка ACID: Дают ту же гарантию целостности данных, что и классические SQL-системы, чего часто не хватает NoSQL.*

### Задание 4. Кластеры
Необходимо производить большое количество вычислений при работе с огромным количеством данных, под эту задачу выделено 1000 машин.

На основе какого критерия будете выбирать тип СУБД и какая модель распределённых вычислений здесь справится лучше всего и почему?

*Ключевой критерий выбора: Модель согласованности данных (CAP-теорема). Нужно выбрать между:  
Точностью данных при любых условиях (CP-системы)  
Непрерывной работой даже ценой временной несогласованности (AP-системы)  
Лучшая модель вычислений: MapReduce (в современных реализациях типа Apache Spark)  
Почему:  
Идеально дробит задачи на тысячи параллельных процессов  
Обрабатывает данные там, где они хранятся  
Автоматически перераспределяет нагрузку при сбоях  
Оптимальное решение: Связка колоночной СУБД (ClickHouse/Cassandra) для хранения + Apache Spark для вычислений.*
